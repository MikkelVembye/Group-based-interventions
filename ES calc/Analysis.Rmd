---
title: Effect size calculation for 'Group-based community interventions to support
  the social reintegration of marginalised adults with mental illness'
date: "Last updated `r format(Sys.time(), '%Y.%m.%d')`"
output: 
  html_document:
    toc: true
    code_folding: show
    code_download: true
bibliography: Group-based interventions.bib
link-citations: yes
fontsize: 11pt
spacing: single
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(message = FALSE)
knitr::opts_chunk$set(warning = FALSE)

options(pillar.sigfig = 4) # ensure tibble include 4 digits
options(tibble.width = Inf)
options(dplyr.print_min = 310)
options(scipen = 10)
options(dplyr.summarise.inform = FALSE) # Avoids summarize info from tidyverse

```

# Load data

```{r}
# Loading the needed data for analysis
group_based_dat <- readRDS("ES calc/Group-based interventions data.RDS") |> 
  # The post-measurement of Empowerment Scale seems flawed for the study by 
  # Barbic et al. 2009 we therefore we exclude it from the analysis
  filter(!(authors == "Barbic et al." & test_name == "The Empowerment Scale"))

```

# Descriptive plots

## Timeline

```{r, echo=FALSE, eval=TRUE, fig.cap='FIGURE 1:  Number of studies included in the meta-analysis by year'}
# Figure 1: Number of included studies in the meta-analysis by year
G_timepllot <- group_based_dat |> 
  group_by(authors) |>  
  summarise(year = unique(year))


timeline_plot <-  ggplot(G_timepllot,aes(x = year)) + 
  geom_bar(colour = "black", fill = "gray70", alpha = 1, width = 1) +
  scale_x_continuous(breaks = seq(2000, 2022, 1)) + 
  scale_y_continuous(breaks = seq(0, 6.5, 1), limits = c(0, 7), expand = c(0,0)) + 
  theme_bw() + 
  theme(
    axis.text.x = element_text(angle = 45, vjust = 1, hjust = 1),
    panel.border = element_blank(),
    legend.position = "none",
    panel.grid.minor = element_blank(),
    panel.grid.major.x = element_blank(),
    axis.line = element_line(colour = "black")
  ) +
  labs(
    x = "Year of Publication",
    y = "Number of Studies"
  ); timeline_plot

```

## Primary study sample size and effective sample sizes (SUPPLEMENTARY MATERIAL)

### Making a effetive sample size (ESS)

```{r}
GBD_effect <- group_based_dat |> 
  filter(variable_type != "Binary") |>
  mutate(
    es_id = 1:n(),
    gt = if_else(!is.na(gt_post), gt_post, NA_real_),
    gt = if_else(!is.na(gt_DD), gt_DD, gt),
    gt = if_else(!is.na(gt_adj), gt_adj, gt),
    gt = if_else(!is.na(gt_reg), gt_reg, gt),
    
    vgt = if_else(!is.na(vgt_post), vgt_post, NA_real_),
    vgt = if_else(!is.na(vgt_DD), vgt_DD, vgt),
    vgt = if_else(!is.na(vgt_adj), vgt_adj, vgt),
    vgt = if_else(!is.na(vgt_reg), vgt_reg, vgt),
    
    Wgt = if_else(!is.na(Wgt_post), Wgt_post, NA_real_),
    Wgt = if_else(!is.na(Wgt_DD), Wgt_DD, Wgt),
    Wgt = if_else(!is.na(Wgt_adj), Wgt_adj, Wgt),
    Wgt = if_else(!is.na(Wgt_reg), Wgt_reg, Wgt)
    
  )

GBD_effect <- GBD_effect|> 
  mutate(
  ESS = round(4/vgt) # Using cluster bias corrected sampling variance
)

# Change Study-id for Gonzalez & Prihoda because of duplicated id
GBD_effect <- GBD_effect %>%
  mutate(studyid = ifelse(authors == "Gonzalez & Prihoda", 500, studyid), 
         cnt = if_else(cnt == "USA", "US", cnt),
         design = ifelse(design  == "QES-pretest","QES", design),
         design = ifelse(design  == "CRCT","RCT", design), 
         assessment = ifelse(assessment == "Self  assesment", "Self assesment", assessment),
         randomization = ifelse(randomization == "Simple Block Randomization", "Block randomized",
                                randomization),
         randomization = ifelse(randomization == "Simple with permuted blocks, stratified by site",
                                "Block randomized stratified by site", randomization),
         randomization = ifelse(randomization == "Stratified?", 
                                "Stratified randomization", randomization),
         trt_type = ifelse(trt_type == "Group-based  Cognitive Behavioral Therapy (CBT)", 
                           "Group based Cognitive Behavioural Therapy", trt_type),
         trt_type = ifelse(trt_type =="Illness management", "Illness Management", trt_type),
         trt_type = ifelse(trt_type =="Social cognition and interaction training", 
                           "Social Cognition and Interaction Training", trt_type))
```

```{r}
sample_size_dat <- 
  GBD_effect %>% 
  group_by(year, studyid, sample_id) %>% 
  summarise_at(
    vars(N_t, N_c, N_total, ESS), list(mean = mean)
    
  )

sample_size_dat %>% 
  pivot_longer(
        cols = N_t_mean:ESS_mean,
    names_to = "sample_sizes_char",
    values_to = "sample_size"
  ) %>% 
  group_by(sample_sizes_char) %>% 
  summarise(
    mean = mean(sample_size, na.rm = TRUE),
    sd = sd(sample_size, na.rm = TRUE),
    q = list(quantile(sample_size, na.rm = TRUE))
  ) %>% 
  unnest_wider(q, names_repair = ~paste0('Q_', sub('%', '', .))) %>% 
  rename(mean = Q_mean, sd = Q_sd) %>% 
  mutate(
    id = rev(1:4)
  ) %>% 
  arrange(id) %>% 
  select(-id)

SS1 <- ggplot(sample_size_dat, aes(N_t_mean)) + 
  geom_density(fill = "cornflowerblue", trim = TRUE) + 
  geom_blank(aes(x = 0, y = 0)) + 
  geom_rug() + 
  theme_minimal() + 
  theme(axis.title.y = element_blank()) +
  labs(x = "Treatment group sample size")

SS2 <- ggplot(sample_size_dat, aes(N_c_mean)) + 
  geom_density(fill = "cornflowerblue", trim = TRUE) + 
  geom_blank(aes(x = 0, y = 0)) + 
  geom_rug() + 
  theme_minimal() +
  theme(axis.title.y = element_blank()) +
  labs(x = "Control group sample size")

SS3 <- ggplot(sample_size_dat, aes(N_total_mean)) + 
  geom_density(fill = "cornflowerblue", trim = TRUE) + 
  geom_blank(aes(x = 0, y = 0)) + 
  geom_rug() + 
  theme_minimal() + 
  theme(axis.title.y = element_blank()) +
  labs(x = "Total sample size")

SS4 <- ggplot(sample_size_dat, aes(ESS_mean)) + 
  geom_density(fill = "cornflowerblue", trim = TRUE) + 
  geom_blank(aes(x = 0, y = 0)) + 
  geom_rug() + 
  theme_minimal() +
  theme(axis.title.y = element_blank()) +
  #scale_x_continuous(breaks = seq(0, 120, 5), limits = c(0, 125)) + 
  labs(x = "Approximate effective sample size (4/SE_total)")

library(patchwork)

sample_dist_plot <- SS1 / SS2 / SS3 / SS4
sample_dist_plot


```

# Empirical distribution of effect size estimates (SUPPLEMENTARY MATERIAL)

```{r}
qrtls <- quantile(GBD_effect$gt, c(.25, .75), na.rm = TRUE)
fences <-  qrtls + 3 * diff(qrtls) * c(-1, 1)
fence_dat <- data.frame(qrtl = qrtls, fence = fences)

es_dist_plot <- 
  ggplot(GBD_effect, aes(gt)) + 
  geom_density(fill = "cornflowerblue") + 
  geom_vline(data = fence_dat, aes(xintercept = qrtl), linetype = "solid") + 
  geom_vline(data = fence_dat, aes(xintercept = fence), linetype = "dashed") + 
  geom_rug(alpha = 0.25) + 
  theme_minimal() + 
  theme(axis.title.y = element_blank()) +
  labs(x = "Effect size estimate")
```

```{r}
# Making data for plotting outcomes


# Without mental health outcomes and only reintergration-outcomes
GB_outcome_reintergration <- GBD_effect |> 
   filter(!str_detect(analysis_plan, "mental|used|hospi")) %>%
  group_by(analysis_plan) |> 
  summarise(
    qrtl = quantile(gt,  c(.25, .75)),
    fence = qrtl + 3 * diff(qrtl) * c(-1,1),
    
    .groups = "drop"
  )


# Therefore All mental health outcomes, Unused outcome and hospitalization are excluded
reintegration_outcome_plot <- GBD_effect %>% 
 filter(!str_detect(analysis_plan, "mental|used|hospi")) %>%
  ggplot(aes(x = gt, fill = analysis_plan)) + 
  geom_density(alpha = 0.7) +
  geom_vline(data = GB_outcome_reintergration, aes(xintercept = qrtl), linetype = "solid")+
  geom_vline(data = GB_outcome_reintergration, aes(xintercept = fence), linetype = "dashed")+
  geom_rug(alpha = 0.25) +
  facet_wrap(~analysis_plan, scales = "free", ncol = 4) +
  theme_minimal() +
  theme(legend.position = "none", axis.title.y = element_blank()) +
  labs(x = "Effect size estimate")


# Plot with all mental health outcomes 

# Total mental health:
GB_outcome_mental_health <- GBD_effect |> 
   filter(str_detect(analysis_plan, "mental")) |> 
  filter(!str_detect(analysis_plan, "Unused")) |>
  summarise(
    qrtl = quantile(gt,  c(.25, .75)),
    fence = qrtl + 3 * diff(qrtl) * c(-1,1),
    
    .groups = "drop"
  )

mental_health_outcome_plot <- GBD_effect %>% 
 filter(str_detect(analysis_plan, "mental")) %>%
  ggplot(aes(x = gt)) + 
  geom_density(alpha = 0.7, fill = "cornflowerblue") +
  geom_vline(data = GB_outcome_mental_health, aes(xintercept = qrtl), linetype = "solid")+
  geom_vline(data = GB_outcome_mental_health, aes(xintercept = fence), linetype = "dashed")+
  geom_rug(alpha = 0.25) +
  theme_minimal() +
  theme(legend.position = "none", axis.title.y = element_blank()) +
  labs(x = "Effect size estimate")

# Seperated mental health outcomes
GB_outcomes_mental_health <- GBD_effect |> 
  mutate(analysis_plan = case_when(
  str_detect(analysis_plan, "All mental health outcomes/Symptoms of psychosis|All mental health outcomes/Negative symptoms") ~ "All mental health outcomes/Symptoms of psychosis",
   TRUE ~ analysis_plan)) |> 
   filter(str_detect(analysis_plan, "mental")) |>
  filter(!str_detect(analysis_plan, "Unused")) |>
  group_by(analysis_plan) |> 
  summarise(
    qrtl = quantile(gt,  c(.25, .75)),
    fence = qrtl + 3 * diff(qrtl) * c(-1,1),
    
    .groups = "drop"
  )


mental_health_outcomes_plot <- GBD_effect |> mutate(analysis_plan = case_when(
  # Gathering negative symptoms and symptoms of psychosis as negative symptoms refers to same symptoms
  str_detect(analysis_plan, "All mental health outcomes/Symptoms of psychosis|All mental health outcomes/Negative symptoms") ~ "All mental health outcomes/Symptoms of psychosis", 
   TRUE ~ analysis_plan)) |> 
  filter(str_detect(analysis_plan, "mental")) |> 
  filter(!str_detect(analysis_plan, "Unused")) |>
  ggplot(aes(x = gt, fill = analysis_plan)) + 
  geom_density(alpha = 0.7) +
  geom_vline(data = GB_outcomes_mental_health, aes(xintercept = qrtl), linetype = "solid")+
  geom_vline(data = GB_outcomes_mental_health, aes(xintercept = fence), linetype = "dashed")+
  geom_rug(alpha = 0.25) +
  facet_wrap(~analysis_plan, scales = "free") +
  theme_minimal() +
  theme(legend.position = "none", axis.title.y = element_blank()) +
  labs(x = "Effect size estimate")
```

# Funnel-plot
```{r}
# Funnel plot for overall effectsizes ----

# data prep
GBD_effect <- GBD_effect |> 
  mutate(timing = case_when(
    timing == "Followup" ~ "3m",
    timing == "Posttest" ~ "Post",
    timing == "12" ~ "12m",
    timing == "24" ~ "24m",
    timing == "post" ~ "Post",
    timing == "3 months" ~ "3m",
    timing == "6 months" ~ "6m",
    timing == "6w" ~ "Post",
    TRUE ~ timing))

unique_values <- unique(GBD_effect$timing)

GB_dat <- 
  GBD_effect |> 
  select(studyid, g = gt, vg = vgt, timing, analysis_plan) |> 
  mutate(
    seg = sqrt(vg),
    timing = if_else(is.na(timing), "Post", timing),
    timing = factor(
      timing, 
      levels = c("Post", "3m", "6m", "9m", "12m", "18m", "24m")
    ),
    es_ID = 1:n()
  ) |> 
  arrange(timing)


#es_exp <- as.numeric(mean_es_GB$b)
y_lim_exp <- max(sqrt(GB_dat$vg)) + 0.02 


funnel_exp <-  tribble(
  ~ x90, ~ x95, ~ x99, ~ y,
  0,     0,     0,     0,
  qnorm(0.05) * y_lim_exp, qnorm(0.025) * y_lim_exp, qnorm(0.005) * y_lim_exp, y_lim_exp,
  qnorm(0.95) * y_lim_exp, qnorm(0.975) * y_lim_exp, qnorm(0.995) * y_lim_exp, y_lim_exp,
  0,     0,     0,     0
) 


GB_plot_all <-
  GB_dat |> 
  ggplot() + 
  geom_polygon(data = funnel_exp, aes(x = y, y = x99), fill = "grey", alpha = 0.5) + 
  geom_polygon(data = funnel_exp, aes(x = y, y = x95), fill = "grey10", alpha = 0.5) + 
  geom_polygon(data = funnel_exp, aes(x = y, y = x90), fill = "lightcyan", alpha = 0.7) + 
  geom_point(aes(seg, g), alpha = 1, size = 1.2) +
  scale_color_brewer(type = "qual", palette = 2) + 
  coord_flip() + 
  scale_x_reverse(limits = c(y_lim_exp, 0.0), expand = c(0,0)) + 
  scale_y_continuous(breaks = seq(-3, 3, 1)) + 
  theme_bw() + 
  labs(x = "Standard error (adjusted)", 
       y = "Standardized mean difference (Hedges' g)", 
       color = "", shape = "") +
  theme(legend.position = "bottom")

# Funnelplot reintegration outcomes - Subgroup analysis ----
GB_dat_reintergration <- 
  GBD_effect |> 
  filter(!str_detect(analysis_plan, "mental|used|hospi|Employment|Physical")) |> 
  select(studyid, g = gt, vg = vgt, timing, analysis_plan) |> 
  mutate(
    seg = sqrt(vg),
    timing = if_else(is.na(timing), "Post", timing),
    timing = factor(
      timing, 
      levels = c("Post", "3m", "6m", "9m", "12m", "18m", "24m")
    ),
    es_ID = 1:n()
  ) |> 
  arrange(timing)



#sub_GB_dat_reintergration <- 
#  GB_dat_reintergration |> 
#  summarise(
#    across(where(is.numeric), mean),
#    .by = analysis_plan
#  ) |> 
#  mutate(
#    Study_ID = 1, 
   # es_exp = as.numeric(mean_es_FP_subgrp$b),
#    slope_upper = qnorm(0.975),
#    slope_lower = qnorm(0.025)
#  )


funnel_exp <-  tribble(
  ~ x90, ~ x95, ~ x99, ~ y,
  0,     0,     0,     0,
  qnorm(0.05) * y_lim_exp, qnorm(0.025) * y_lim_exp, qnorm(0.005) * y_lim_exp, y_lim_exp,
  qnorm(0.95) * y_lim_exp, qnorm(0.975) * y_lim_exp, qnorm(0.995) * y_lim_exp, y_lim_exp,
  0,     0,     0,     0
) 


# Overall effect-size for reintegration outcome
FP_plot_reintegration_overall <-
  GB_dat_reintergration |> 
  ggplot() + 
  geom_polygon(data = funnel_exp, aes(x = y, y = x99), fill = "grey", alpha = 0.5) + 
  geom_polygon(data = funnel_exp, aes(x = y, y = x95), fill = "grey10", alpha = 0.5) + 
  geom_polygon(data = funnel_exp, aes(x = y, y = x90), fill = "lightcyan", alpha = 0.7) + 
  geom_point(aes(seg, g), alpha = 1, size = 1.2) +
  scale_color_brewer(type = "qual", palette = 2) + 
  coord_flip() + 
  scale_x_reverse(limits = c(y_lim_exp, 0.0), expand = c(0,0)) + 
  scale_y_continuous(breaks = seq(-3, 3, 1)) + 
  theme_bw() + 
  labs(x = "Standard error (adjusted)", 
       y = "Standardized mean difference (Hedges' g)", 
       color = "", shape = "") +
  theme(legend.position = "none")


# Effect-sizes for separated reintegration outcome
FP_plot_reintergration_subgrp <-
  GB_dat_reintergration |> 
  ggplot() + 
  geom_polygon(data = funnel_exp, aes(x = y, y = x99), fill = "grey", alpha = 0.5) + 
  geom_polygon(data = funnel_exp, aes(x = y, y = x95), fill = "grey10", alpha = 0.5) + 
  geom_polygon(data = funnel_exp, aes(x = y, y = x90), fill = "lightcyan", alpha = 0.7) + 
  geom_point(aes(seg, g), alpha = 1, size = 1.2) +
  scale_color_brewer(type = "qual", palette = 2) + 
  coord_flip() + 
  facet_grid(~analysis_plan, scales = "free") +
  scale_x_reverse(limits = c(y_lim_exp, 0.0), expand = c(0,0)) + 
  scale_y_continuous(breaks = seq(-3, 3, 1)) + 
  theme_bw() + 
  labs(x = "Standard error (adjusted)", 
       y = "Standardized mean difference (Hedges' g)", 
       color = "", shape = "") +
  theme(legend.position = "none")

# Funnel-plot health outcomes - Subgroup analysis ----
GB_dat_mental_health <- 
  GBD_effect |> 
  mutate(analysis_plan = case_when(
  str_detect(analysis_plan, "All mental health outcomes/Symptoms of psychosis|All mental health outcomes/Negative symptoms") ~ "All mental health outcomes/Symptoms of psychosis",
   TRUE ~ analysis_plan)) |> 
  filter(str_detect(analysis_plan, "mental")) |>
  filter(!str_detect(analysis_plan, "Unused")) |>
  select(studyid, g = gt, vg = vgt, timing, analysis_plan) |> 
  mutate(
    seg = sqrt(vg),
    timing = if_else(is.na(timing), "Post", timing),
    timing = factor(
      timing, 
      levels = c("Post", "3m", "6m", "9m", "12m", "18m", "24m")
    ),
    es_ID = 1:n()
  ) |> 
  arrange(timing)


funnel_exp <-  tribble(
  ~ x90, ~ x95, ~ x99, ~ y,
  0,     0,     0,     0,
  qnorm(0.05) * y_lim_exp, qnorm(0.025) * y_lim_exp, qnorm(0.005) * y_lim_exp, y_lim_exp,
  qnorm(0.95) * y_lim_exp, qnorm(0.975) * y_lim_exp, qnorm(0.995) * y_lim_exp, y_lim_exp,
  0,     0,     0,     0
) 


# Overall effect size for mental health outcome
FP_plot_overall_mental <-
  GB_dat_mental_health |> 
  ggplot() + 
  geom_polygon(data = funnel_exp, aes(x = y, y = x99), fill = "grey", alpha = 0.5) + 
  geom_polygon(data = funnel_exp, aes(x = y, y = x95), fill = "grey10", alpha = 0.5) + 
  geom_polygon(data = funnel_exp, aes(x = y, y = x90), fill = "lightcyan", alpha = 0.7) + 
  geom_point(aes(seg, g), alpha = 1, size = 1.2) +
  scale_color_brewer(type = "qual", palette = 2) + 
  coord_flip() + 
  scale_x_reverse(limits = c(y_lim_exp, 0.0), expand = c(0,0)) + 
  scale_y_continuous(breaks = seq(-3, 3, 1)) + 
  theme_bw() + 
  labs(x = "Standard error (adjusted)", 
       y = "Standardized mean difference (Hedges' g)", 
       color = "", shape = "") +
  theme(legend.position = "none")

# Subgroup effect size for mental health outcome
FP_plot_subgrp_mental <-
  GB_dat_mental_health |> 
  filter(!(analysis_plan == "All mental health outcomes")) |>
  ggplot() + 
  geom_polygon(data = funnel_exp, aes(x = y, y = x99), fill = "grey", alpha = 0.5) + 
  geom_polygon(data = funnel_exp, aes(x = y, y = x95), fill = "grey10", alpha = 0.5) + 
  geom_polygon(data = funnel_exp, aes(x = y, y = x90), fill = "lightcyan", alpha = 0.7) + 
  geom_point(aes(seg, g), alpha = 1, size = 1.2) +
  scale_color_brewer(type = "qual", palette = 2) + 
  coord_flip() + 
  facet_grid(~analysis_plan, scales = "free") +
  scale_x_reverse(limits = c(y_lim_exp, 0.0), expand = c(0,0)) + 
  scale_y_continuous(breaks = seq(-3, 3, 1)) + 
  theme_bw() + 
  labs(x = "Standard error (adjusted)", 
       y = "Standardized mean difference (Hedges' g)", 
       color = "", shape = "") +
  theme(legend.position = "none")

```

# Desriptive Tables 
```{r}
# Study context

# Percent studies by countries
country_all <- GBD_effect |> 
  group_by(studyid, cnt) |> 
  summarise(
    es_n = n(),
    
    .groups = "drop"
  ) |> 
  group_by(cnt) |>
  summarise(
    study_char = "Percentage of studies by countries",
    
    I = n_distinct(studyid),
    K = sum(es_n),
    
    Mean = I/n_distinct(GBD_effect$studyid),
    SD = NA,
    
    range = "0-1",
    
    .groups = "drop"
  ); country_all


# Average number of participants per effect size 

participants <- GBD_effect |> 
  group_by(studyid) |> 
  summarise(
    study_avg_sample = mean(N_total),
    es_n = n(), 
    .groups = "drop"
  ) |> 
  summarise(
    study_char = "Number of particiapnts",
    
    I = n_distinct(studyid),
    K = sum(es_n),
    
    Mean = round(mean(study_avg_sample)),
    SD = round(sd(study_avg_sample)),
    
    range = paste0(min(study_avg_sample), "-", max(study_avg_sample))
    
  ); participants

# Effective sample size 
ESS <- GBD_effect |> 
  group_by(studyid) |> 
  summarise(
    study_avg_ESS = mean(ESS),
    
    es_n = n(),
    
    .groups = "drop"
  ) |> 
  summarise(
    study_char = "Effective sample size",
    
    I = n_distinct(studyid),
    K = sum(es_n),
    
    Mean = round(mean(study_avg_ESS)),
    SD = round(sd(study_avg_ESS)),
    
    range = paste0(min(study_avg_ESS), "-", round(max(study_avg_ESS)))
    
  ); ESS

# Average size of the groups
group_size <- GBD_effect |> 
  group_by(studyid) |> 
  summarise(
    treat_SampS = mean(N_t),
    cont_SampS = mean(N_c),
    
    es_n = n(),
    
    .groups = "drop"
  ) |> 
  summarise(
    study_char = c("Intervention group", "Control group"),
    
    I = n_distinct(studyid),
    K = sum(es_n),
    
    Mean = c(mean(treat_SampS), mean(cont_SampS)),
    SD = c(sd(treat_SampS), sd(cont_SampS)),
    
    range = c(
      paste0(min(treat_SampS), "-", round(max(treat_SampS))),
      paste0(min(cont_SampS), "-", round(max(cont_SampS)))
    )
    
  ); group_size

# Number of samples per study 
samples_per_study <- GBD_effect |> 
  group_by(studyid) |> 
  summarise(
    samples = n_distinct(sample_id), 
    es_n = n(),
    
    .groups = "drop"
  ) %>%
  summarise(
    study_char = "Number of samples per study",
    
    I = sum(samples),  
    K = sum(es_n),  
    
    Mean = mean(samples), 
    SD = sd(samples),  
    
    range = paste0(min(samples), "-", max(samples)),
    
    .groups = "drop"
  ); samples_per_study


# Number of distinct studies in review

n_distinct(GBD_effect$studyid)

study_context <- 
  bind_rows(
    country_all,
    participants,
    ESS,
    group_size,
    samples_per_study
    
); study_context


```

## Descriptive of studies design
```{r}

# Proportion cluster randomized or RCT studies

study_design <- GBD_effect |>  
  group_by(studyid) %>% 
  summarise(
    design = unique(design),
    es_n = n(),
    
    .groups = "drop"
    
  ) %>% 
  group_by(design) %>% 
  summarise(

    I = n_distinct(studyid),
    K = sum(es_n),
    
  ) %>% 
  mutate(
    
    study_char = paste("%", design),
    
    Mean = I/n_distinct(GBD_effect$studyid),
    SD = NA,
    range = "0-1",
    
   ) |> 
  relocate(study_char) %>% 
  select(-c(design)); study_design

# Dont no if relevant to show details about study outlet and publishment as
# Every indcluded study is a journal article and published. 

# Randomization
study_randomization <- GBD_effect |>  
  group_by(studyid) %>% 
  summarise(
    randomization = unique(randomization),
    es_n = n(),
    
    .groups = "drop"
    
  ) %>% 
  group_by(randomization) %>% 
  summarise(

    I = n_distinct(studyid),
    K = sum(es_n),
    
  ) %>% 
  mutate(
    
    study_char = paste("%", randomization),
    
    Mean = I/n_distinct(GBD_effect$studyid),
    SD = NA,
    range = "0-1",
    
   ) |> 
  relocate(study_char) %>% 
  select(-c(randomization)); study_randomization


```

## Participants characteristics 
```{r}
# % Males in treatment and control group

male_per <- 
  GBD_effect %>% 
  group_by(studyid) %>% 
  summarise(
    
    t_male = mean(as.numeric(male_pct_t), na.rm = TRUE),
    c_male = mean(as.numeric(male_pct_c), na.rm = TRUE),
    
     es_n = sum(!is.na(male_pct_t)),
    
    .groups = "drop"
    
  ) %>% 
  filter(es_n != 0) %>% 
   summarise(
    study_char = c("Intervention group", "Control group"),  # Kategorier for hver gruppe
    I = n_distinct(studyid),  
    K = sum(es_n, na.rm = TRUE),
    
    Mean = c(mean(t_male, na.rm = TRUE), mean(c_male, na.rm = TRUE)),  # Gennemsnit for hver gruppe
    SD = c(sd(t_male, na.rm = TRUE), sd(c_male, na.rm = TRUE)),  # Standardafvigelse for hver gruppe
    range = c(paste(min(t_male, na.rm = TRUE), "-", max(t_male, na.rm = TRUE)),  # Range for hver gruppe
              paste(min(c_male, na.rm = TRUE), "-", max(c_male, na.rm = TRUE)))
  ); male_per

# Mean age
age_mean <- 
  GBD_effect %>% 
  group_by(studyid) %>% 
  summarise(
    
    t_age = mean(as.numeric(age_mean_t), na.rm = TRUE),
    c_age = mean(as.numeric(age_mean_c), na.rm = TRUE),
    
     es_n = sum(!is.na(age_mean_c)),
    
    .groups = "drop"
    
  ) %>% 
  filter(es_n != 0) %>% 
   summarise(
    study_char = c("Intervention group", "Control group"),  # Kategorier for hver gruppe
    I = n_distinct(studyid),  
    K = sum(es_n, na.rm = TRUE),
    
    Mean = c(mean(t_age, na.rm = TRUE), mean(c_age, na.rm = TRUE)),  # Gennemsnit for hver gruppe
    SD = c(sd(t_age, na.rm = TRUE), sd(c_age, na.rm = TRUE)),  # Standardafvigelse for hver gruppe
    range = c(paste(min(t_age, na.rm = TRUE), "-", max(t_age, na.rm = TRUE)),  # Range for hver gruppe
              paste(min(c_age, na.rm = TRUE), "-", max(c_age, na.rm = TRUE)))
  ); age_mean

# Disorder type
disorder_type <- GBD_effect |>  
  group_by(studyid) %>% 
  summarise(
    disorder = unique(disorder_type),
    es_n = n(),
    
    .groups = "drop"
    
  ) %>% 
  group_by(disorder) %>% 
  summarise(

    I = n_distinct(studyid),
    K = sum(es_n),
    
  ) %>% 
  mutate(
    
    study_char = paste("%", disorder),
    
    Mean = I/n_distinct(GBD_effect$studyid),
    SD = NA,
    range = "0-1",
    
   ) |> 
  relocate(study_char) %>% 
  select(-c(disorder)); disorder_type


assesment <- GBD_effect |>  
  group_by(studyid) %>% 
  summarise(
    assessment = unique(assessment),
    es_n = n(),
    
    .groups = "drop"
    
  ) %>% 
  group_by(assessment) %>% 
  summarise(

    I = n_distinct(studyid),
    K = sum(es_n),
    
  ) %>% 
  mutate(
    
    study_char = paste("%", assessment),
    
    Mean = I/n_distinct(GBD_effect$studyid),
    SD = NA,
    range = "0-1",
    
   ) |> 
  relocate(study_char) %>% 
  select(-c(assessment)); assesment

# Sample composition
sample_composition <- GBD_effect |>  
  group_by(studyid) %>% 
  summarise(
    composition = unique(sample_comp),
    es_n = n(),
    
    .groups = "drop"
    
  ) %>% 
  group_by(composition) %>% 
  summarise(

    I = n_distinct(studyid),
    K = sum(es_n),
    
  ) %>% 
  mutate(
    
    study_char = paste("%", composition),
    
    Mean = I/n_distinct(GBD_effect$studyid),
    SD = NA,
    range = "0-1",
    
   ) |> 
  relocate(study_char) %>% 
  select(-c(composition)); sample_composition

# Sample factors
sample_factors <- GBD_effect |>  
  group_by(studyid) %>% 
  summarise(
    sample_factors = unique(sample_factors),
    es_n = n(),
    
    .groups = "drop"
    
  ) %>% 
  group_by(sample_factors) %>% 
  summarise(

    I = n_distinct(studyid),
    K = sum(es_n),
    
  ) %>% 
  mutate(
    
    study_char = paste("%", sample_factors),
    
    Mean = I/n_distinct(GBD_effect$studyid),
    SD = NA,
    range = "0-1",
    
   ) |> 
  relocate(study_char) %>% 
  select(-c(sample_factors)); sample_factors

```
## Intervention characteristics
```{r}
# Duration of intervention
duration <- 
  GBD_effect %>% 
  group_by(studyid) %>% 
  summarise(
    
    m_duration_J = mean(duration_weeks, na.rm = TRUE),
  
    es_n = n(),
    
    miss_dur = sum(is.na(duration_weeks)),
    
    dur_report = if_else(miss_dur == 0, "Reported", "Not reported"),
    
    .groups = "drop"
     
  ) %>% 
  filter(dur_report != "Not reported") %>% 
  summarise(
    
    study_char = "Duration in weeks",
    
    #J = n_distinct(study_year),
    I = n_distinct(studyid),
    K = sum(es_n),
    
    Mean = mean(m_duration_J, na.rm = TRUE),
    SD = sd(m_duration_J, na.rm = TRUE),
    
    range = paste0(min(m_duration_J, na.rm = TRUE), "-",
                   max(m_duration_J, na.rm = TRUE)),
    
    #Median = round(median(m_duration_J, na.rm = TRUE)),
    #IQR = IQR(m_duration_J, na.rm = TRUE),
    
  ); duration

# Mean number of sessions per week

sessions_per_week <- 
  GBD_effect|> 
  mutate(sessions_per_week = as.numeric(sessions_per_week)) |> 
  group_by(studyid)  |>  
  summarise(
    
    m_intensity_J = mean(sessions_per_week, na.rm = TRUE),
  
    es_n = n(),
    
    miss_int = sum(is.na(sessions_per_week)),
    
    int_report = if_else(miss_int == 0, "Reported", "Not reported"),
    
    .groups = "drop"
     
  ) %>% 
  filter(int_report != "Not reported") |>  
  summarise(
    
    study_char = "Number of sessions per week",
    
    I = n_distinct(studyid),
    K = sum(es_n),
    
    Mean = mean(m_intensity_J, na.rm = TRUE),
    SD = sd(m_intensity_J, na.rm = TRUE),
    
    range = paste0(min(m_intensity_J, na.rm = TRUE), "-",
                   max(m_intensity_J, na.rm = TRUE))
    
  ); sessions_per_week

# Average group size in the treatment intervention
avg_intevention_group_size <- 
  GBD_effect|> 
  mutate(avg_group_size = as.numeric(avg_group_size)) |> 
  group_by(studyid)  |>  
  summarise(
    
    m_intensity_J = mean(avg_group_size, na.rm = TRUE),
  
    es_n = n(),
    
    miss_int = sum(is.na(avg_group_size)),
    
    int_report = if_else(miss_int == 0, "Reported", "Not reported"),
    
    .groups = "drop"
     
  ) %>% 
  filter(int_report != "Not reported") |>  
  summarise(
    
    study_char = "Average group size in interventions",
    
    I = n_distinct(studyid),
    K = sum(es_n),
    
    Mean = mean(m_intensity_J, na.rm = TRUE),
    SD = sd(m_intensity_J, na.rm = TRUE),
    
    range = paste0(min(m_intensity_J, na.rm = TRUE), "-",
                   max(m_intensity_J, na.rm = TRUE))
    
  ); avg_intevention_group_size

# Treatment types 
treatment_types <- GBD_effect |>  
  group_by(studyid) %>% 
  summarise(
    treatment_type = unique(trt_type),
    es_n = n(),
    
    .groups = "drop"
    
  ) %>% 
  group_by(treatment_type) %>% 
  summarise(

    I = n_distinct(studyid),
    K = sum(es_n),
    
  ) %>% 
  mutate(
    
    study_char = paste("%", treatment_type),
    
    Mean = I/n_distinct(GBD_effect$studyid),
    SD = NA,
    range = "0-1",
    
   ) |> 
  relocate(study_char) %>% 
  select(-c(treatment_type)); treatment_types

```

## Methodological features